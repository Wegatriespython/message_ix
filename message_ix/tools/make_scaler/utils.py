import os

import numpy as np
import pandas as pd


def filter_df(data, bounds):
    """Extracts matrix elements with coefficient outliers.

    This function extracts elements from a matrix where
    the coefficients deviate from a specified threshold.

    Parameters:
    -----------
    data : pandas DataFrame
        The coefficient matrix, typically generated by
        the mps_sum function in LPDiag.
    bounds: int or list of 2 integers
        Exponent threshold used to identify outlier coefficients.
        If a single integer is provided, the bounds are set to +/- that value.
        If a list of 2 integers is provided, they represent the lower and
        upper bounds of the threshold.

    Examples:
    ---------
    # Extract elements with coefficient exponents deviating beyond +/-3
    extracted_data = filter_df(data_matrix, 3)

    # Extract elements with coefficients exponents deviating
    # beyond the range of -2 to 2
    extracted_data = extract_outliers(data_matrix, [-2, 2])
    """

    if isinstance(bounds, int):
        lo_bound = -bounds
        up_bound = bounds
    else:
        lo_bound = bounds[0]
        up_bound = bounds[1]

    # Use .values for faster numpy array access
    arr = data["val"].values
    mask = (arr <= lo_bound) | (arr >= up_bound)
    return data.loc[mask]


def make_logdf(data):
    """
    Optimized log10 of the absolute non zero value element of dataframe.

    """
    # Use .values for faster numpy array access
    arr = data["val"].values
    mask = arr != 0
    log_arr = np.zeros_like(arr, dtype=float)
    log_arr[mask] = np.log10(np.abs(arr[mask]))
    # Avoid DataFrame reconstruction - modify in place if possible
    result = data.copy()
    result["val"] = log_arr
    return result


def get_lvl_ix(data, lvl):
    """
    To get level index from coefficient matrix.

    Parameters:
    -----------
    data : pandas DataFrame
        The coefficient matrix, typically generated by
        the mps_sum function in LPDiag.
    lvl : int or str
        0 or "row" for rows and 1 or "col" for columns

    """
    return data.index.get_level_values(lvl)


def show_range(data, pretext):
    """
    To displace coefficient exponents range.

    """
    # Optimize: avoid creating full log dataframe
    arr = data["val"].values
    mask = arr != 0
    if mask.any():
        log_vals = np.log10(np.abs(arr[mask]))
        min_val = np.int32(np.min(log_vals))
        max_val = np.int32(np.max(log_vals))
    else:
        min_val = max_val = 0

    print(
        f"{pretext}:",
        "[",
        min_val,  # lower bound
        "|",
        max_val,  # upper bound
        "]",
    )


def get_scaler_args(
    scenario_ref_model=None, scenario_ref_scenario=None, model="", scenario=""
):
    """
    Function to make gams argument for scaling

    """
    if not scenario_ref_model:
        strings = ["MsgScaler", model, scenario]
    else:
        strings = ["MsgScaler", scenario_ref_model, scenario_ref_scenario]

    file_name = "_".join(s.replace(" ", "_") for s in strings)
    prescale_args_dir = os.path.join(f"message_ix/model/scaler/{file_name}.gms")

    if os.path.exists(prescale_args_dir):
        return f"--scaler={file_name}"
    else:
        print(f" I am here {os.getcwd()}")
        print(f"could not find file at {prescale_args_dir} ")
        print("The referred scenario doesn't have prescaler file!")
        print("Please use make_prescaler() function to create one")


def replace_spaces_in_quotes(match):
    inner_text = match.group(1)
    return f"'{inner_text.replace(' ', '___')}'"


def return_spaces_in_quotes(match):
    inner_text = match.group(1)
    return f"'{inner_text.replace('---', ' ')}'"


def _process_scaling_step(matrix, scalers, s, bounds, counter, display_range):
    """Process a single scaling step for rows or columns using optimized operations."""
    log_absmatrix = make_logdf(matrix)
    log_absmatrix_solv = filter_df(log_absmatrix, bounds)

    objective_ix = "_obj" if s == "row" else "constobj"
    levels_solv = [
        lvl for lvl in get_lvl_ix(log_absmatrix_solv, s) if lvl != objective_ix
    ]

    if levels_solv:
        # Optimization: Only group the rows/cols that need scaling
        # First get all indices at the specified level
        all_indices = get_lvl_ix(log_absmatrix, s)
        # Create a mask for rows/cols we want to process
        mask = all_indices.isin(levels_solv)
        filtered_matrix = log_absmatrix[mask]
        
        # Now group only the filtered data
        grp = filtered_matrix["val"].groupby(level=s)
        bounds_df = grp.agg(["min", "max"]).astype(int)
        mids = ((bounds_df["min"] + bounds_df["max"]) / 2).astype(int)
        exps = mids if s == "row" else -mids
        
        # Vectorized power operation
        SFs = pd.Series(10.0**exps, index=exps.index).to_dict()
    else:
        SFs = {}

    return_index = list(set(get_lvl_ix(log_absmatrix, s)))
    
    # Optimization: Avoid creating new DataFrame for scalers if possible
    if counter == 0:
        # First iteration - create new scaler
        step_scaler = pd.Series(1.0, index=return_index)
        step_scaler.update(pd.Series(SFs))
        step_scaler = pd.DataFrame({"val": step_scaler})
        step_scaler.index.name = s
    else:
        # Subsequent iterations - update existing
        multiplier = scalers[s].reindex(return_index).fillna(1)
        step_scaler = pd.DataFrame({"val": pd.Series(SFs, index=return_index).fillna(1.0)})
        step_scaler.index.name = s
        step_scaler = step_scaler.mul(multiplier)

    scalers[s] = step_scaler
    
    # Optimization: Use values for arithmetic operations
    if s == "row":
        matrix = matrix.div(step_scaler)
    else:
        matrix = matrix.mul(step_scaler)
    
    return matrix
