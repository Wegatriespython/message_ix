import os
import re

import numpy as np
import pandas as pd

from message_ix.tools.lp_diag import LPdiag


def filter_df(data, bounds):
    """Extracts matrix elements with coefficient outliers.

    This function extracts elements from a matrix where
    the coefficients deviate from a specified threshold.

    Parameters:
    -----------
    data : pandas DataFrame
        The coefficient matrix, typically generated by
        the mps_sum function in LPDiag.
    bounds: int or list of 2 integers
        Exponent threshold used to identify outlier coefficients.
        If a single integer is provided, the bounds are set to +/- that value.
        If a list of 2 integers is provided, they represent the lower and
        upper bounds of the threshold.

    Examples:
    ---------
    # Extract elements with coefficient exponents deviating beyond +/-3
    extracted_data = filter_df(data_matrix, 3)

    # Extract elements with coefficients exponents deviating
    # beyond the range of -2 to 2
    extracted_data = extract_outliers(data_matrix, [-2, 2])
    """

    if isinstance(bounds, int):
        lo_bound = -bounds
        up_bound = bounds
    else:
        lo_bound = bounds[0]
        up_bound = bounds[1]

    arr = data["val"].to_numpy()
    mask = (arr <= lo_bound) | (arr >= up_bound)
    return data.loc[mask]


def make_logdf(data):
    """
    Optimized log10 of the absolute non zero value element of dataframe.

    """
    arr = data["val"].to_numpy()
    mask = arr != 0
    log_arr = np.zeros_like(arr, dtype=float)
    log_arr[mask] = np.log10(np.abs(arr[mask]))
    return pd.DataFrame({"val": log_arr}, index=data.index)


def get_lvl_ix(data, lvl):
    """
    To get level index from coefficient matrix.

    Parameters:
    -----------
    data : pandas DataFrame
        The coefficient matrix, typically generated by
        the mps_sum function in LPDiag.
    lvl : int or str
        0 or "row" for rows and 1 or "col" for columns

    """
    return data.index.get_level_values(lvl)


def show_range(data, pretext):
    """
    To displace coefficient exponents range.

    """

    log_absdf = make_logdf(data)

    print(
        f"{pretext}:",
        "[",
        np.int32(np.min(log_absdf)),  # lower bound
        "|",
        np.int32(np.max(log_absdf)),  # upper bound
        "]",
    )


def get_scaler_args(
    scenario_ref_model=None, scenario_ref_scenario=None, model="", scenario=""
):
    """
    Function to make gams argument for scaling

    """
    if not scenario_ref_model:
        strings = ["MsgScaler", model, scenario]
    else:
        strings = ["MsgScaler", scenario_ref_model, scenario_ref_scenario]

    file_name = "_".join(s.replace(" ", "_") for s in strings)
    prescale_args_dir = os.path.join(f"message_ix/model/scaler/{file_name}.gms")

    if os.path.exists(prescale_args_dir):
        return f"--scaler={file_name}"
    else:
        print(f" I am here {os.getcwd()}")
        print(f"could not find file at {prescale_args_dir} ")
        print("The referred scenario doesn't have prescaler file!")
        print("Please use make_prescaler() function to create one")


def replace_spaces_in_quotes(match):
    inner_text = match.group(1)
    return f"'{inner_text.replace(' ', '___')}'"


def return_spaces_in_quotes(match):
    inner_text = match.group(1)
    return f"'{inner_text.replace('---', ' ')}'"


def _process_scaling_step(matrix, scalers, s, bounds, counter, display_range):
    """Process a single scaling step for rows or columns using optimized operations."""
    log_absmatrix = make_logdf(matrix)
    log_absmatrix_solv = filter_df(log_absmatrix, bounds)

    objective_ix = "_obj" if s == "row" else "constobj"
    levels_solv = [
        lvl for lvl in get_lvl_ix(log_absmatrix_solv, s) if lvl != objective_ix
    ]

    if levels_solv:
        grp = log_absmatrix["val"].groupby(level=s)
        bounds_df = grp.agg(["min", "max"]).astype(int)
        mids = ((bounds_df["min"] + bounds_df["max"]) / 2).astype(int)
        exps = mids if s == "row" else -mids
        SFs = (10.0**exps).to_dict()
        SFs = {k: v for k, v in SFs.items() if k in levels_solv}
    else:
        SFs = {}

    return_index = list(set(get_lvl_ix(log_absmatrix, s)))
    multiplier = 1 if counter == 0 else scalers[s].reindex(return_index).fillna(1)

    step_scaler = pd.DataFrame(data=SFs, index=["val"]).transpose()
    step_scaler.index.name = s
    step_scaler = step_scaler.reindex(return_index).fillna(1)

    scalers[s] = step_scaler.mul(multiplier)
    matrix = matrix.div(step_scaler) if s == "row" else matrix.mul(step_scaler)
    return matrix


def make_scaler(path, scen_model, scen_scenario, bounds=4, steps=1, display_range=True):
    """
    Process to generate prescale_args in GAMS to improve
    matrix coefficients.

    This function shifts matrix coefficient exponents to improve
    the scaling properties of the matrix. The function returns
    prescale arguments (prescale_args) to be passed to the GAMS model.

    Parameters:
    -----------
    path: str
        Pathways to locate the mps file.
    bounds: int or list of 2 integers
        Exponent threshold used to identify outlier coefficients.
        If a single integer is provided, the bounds are set to +/- that value.
        If a list of 2 integers is provided, they represent
        the lower and upper bounds of the threshold.
    steps: int
        Number of times the prescaler generation process is repeated.
        Larger values may lead to more refined prescale_args but
        also increase computation time.
    show_range: boolean
        Option to show the coefficient exponents range before and after scaling.
        If True, the function will display the range; otherwise, it will not.

    Returns:
    --------
    prescale_args: dict
        A dictionary of prescale arguments to be passed to the GAMS model.
    """

    # Aligning mps file content with lp_diag naming formats
    quoted_pattern = re.compile(r"'([^']*)'")

    with open(path, "r+") as f:
        old = f.readlines()  # Pull the file contents to a list
        f.seek(0)  # Jump to start, so we overwrite instead of appending
        f.truncate()  # Clear the file before writing
        for line in old:
            # Replace spaces inside single-quoted substrings
            new_line = quoted_pattern.sub(replace_spaces_in_quotes, line)
            f.write(new_line)
    lp = LPdiag()
    # Start making the scaler
    lp.read_mps(path)

    data = lp.read_matrix()

    matrix = data

    if display_range is True:
        show_range(matrix, "\nUnscaled range     ")

    scalers = {"row": [], "col": []}

    counter = 0
    while counter < steps:
        for s in scalers.keys():
            matrix = _process_scaling_step(
                matrix, scalers, s, bounds, counter, display_range
            )

        if display_range is True:
            show_range(matrix, f"Scaled range step {counter + 1}")

        counter += 1

    # generating prescaler arguments for GAMS
    scaler_dict = {}
    for key, df_scaler in scalers.items():
        df_scaler = df_scaler.loc[df_scaler["val"] != 1]
        for k, v in df_scaler["val"].to_dict().items():
            if k == "_obj":
                k_ = "_obj.scale"
            elif k == "constobj":
                k_ = "constobj.scale"
            else:
                # Check if this is a multi-dimensional constraint (has parentheses)
                if "(" in k and ")" in k:
                    # Extract constraint name and parameters
                    constraint_name = k[: k.index("(")]
                    params = k[k.index("(") + 1 : k.index(")")].split(",")
                    # Quote each parameter only if not already quoted
                    quoted_params = []
                    for p in params:
                        p = p.strip()
                        if p.startswith("'") and p.endswith("'"):
                            # Already quoted, use as-is
                            quoted_params.append(p)
                        else:
                            # Not quoted, add quotes
                            quoted_params.append(f"'{p}'")
                    # Reconstruct with quotes
                    k_ = f"{constraint_name}.scale({','.join(quoted_params)})"
                else:
                    # Simple constraint name without dimensions
                    k_ = k + ".scale"
            # Note: We do NOT replace ___ with spaces to avoid breaking strings
            scaler_dict[k_] = v

    # add this line to active scaling option
    scaler_dict["MESSAGE_LP.scaleopt"] = 1

    scaler_df = pd.DataFrame(scaler_dict, index=["val"]).transpose()
    scaler_df.index = scaler_df.index.rename("key", inplace=False)

    scaler_list = [f"{k}={v};" for k, v in scaler_dict.items()]
    scaler_args_txt = "\n".join(scaler_list)

    # Find the message_ix root directory by looking for the model/scaler directory
    current_file = os.path.abspath(__file__)
    # Go up from tools/make_scaler/__init__.py to message_ix root
    message_ix_root = os.path.dirname(os.path.dirname(os.path.dirname(current_file)))

    scaler_gms_name = "_".join(s.replace(" ", "_") for s in [scen_model, scen_scenario])

    scaler_dir = os.path.join(message_ix_root, "model", "scaler")
    os.makedirs(scaler_dir, exist_ok=True)  # Create directory if it doesn't exist

    scaler_gms_dir = os.path.join(scaler_dir, f"MsgScaler_{scaler_gms_name}.gms")

    with open(scaler_gms_dir, "w") as txtfile:
        # Write some text to the file
        txtfile.write(scaler_args_txt)

    return scaler_df
